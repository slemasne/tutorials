{
  
    
        "post0": {
            "title": "Testing the match case statements",
            "content": "In this tutorial, we&#39;ll take a look at the new match-case statement released in Python 3.10. . We&#39;ll look at: . What is the match-case statement? | What features does it have? | Why would you use match-case over an if-else statement? | 1. What is the match-case statement? . On the surface it looks very simliar to an if-else statement. You provide some conditions, and the statement retuns a value if those conditions are met. For example, here we have a match-case to match the London TFL tube to that line&#39;s official colour. . def find_tube(tube_line_colour): match tube_line_colour: case &quot;black&quot;: return &quot;northern&quot; case &quot;red&quot; | &quot;orange&quot;: return &quot;central&quot; case _: return &quot;unknown&quot; . display(find_tube(&quot;red&quot;)) display(find_tube(&quot;darkgreen&quot;)) . &#39;central&#39; . &#39;unknown&#39; . We could also implement the same logic using an if-else statement: . def find_tube(tube_line_colour): if tube_line_colour == &quot;black&quot;: return &quot;northern&quot; elif tube_line_colour == &quot;red&quot; or tube_line_colour == &quot;orange&quot;: return &quot;central&quot; else: return &quot;unknown&quot; . display(find_tube(&quot;red&quot;)) display(find_tube(&quot;darkgreen&quot;)) . &#39;central&#39; . &#39;unknown&#39; . 2. What features does it have? .",
            "url": "https://fastpages.fast.ai/tutorials/2022/06/27/match-case.html",
            "relUrl": "/2022/06/27/match-case.html",
            "date": " • Jun 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://fastpages.fast.ai/tutorials/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Measuring Equity Risk",
            "content": "In this notebook we&#39;ll explore two statistical methods for calculating Equity Risk: . Variance: fluctuation of stock return from its mean | VaR: the maximum an investor could loose (within a confidence interval) | For the purposes of this notebook, we&#39;ll explore the above looking at the risk of Apple (ticker = AAPL). . Import packages and setup configurations . import pandas as pd import quandl import datetime import matplotlib.pyplot as plt import seaborn as sns import os from sklearn import linear_model plt.style.use(&#39;fivethirtyeight&#39;) from statsmodels.formula.api import ols # Use Python&#39;s &quot;magic&quot; commands since we want to see the graphs within this notebook %matplotlib inline %pylab inline pylab.rcParams[&quot;figure.figsize&quot;] = (8,6) . Populating the interactive namespace from numpy and matplotlib . directory = os.getcwd() + &quot;/data/&quot; # CSV file contained within local directory .",
            "url": "https://fastpages.fast.ai/tutorials/2018/03/03/measure-equity-risk.html",
            "relUrl": "/2018/03/03/measure-equity-risk.html",
            "date": " • Mar 3, 2018"
        }
        
    
  
    
        ,"post3": {
            "title": "SVP100 - Hitting The Wall",
            "content": "SVP100 - Hitting The Wall . In August of 2017 I ran the SVP100. This is a 100KM trail running race starting in Newmarket (Suffolk, UK) and ending in Manning Tree (Essex, UK). In regular distance marathons, its widely believed runners “hit the wall” at around 30KM mark (or 70% through the race). In this notebook, I want to see if the same holds true over a 100KM distance. . From a high level, the code below performs the following: . Scrape results data from the race website (using Beautiful Soup) . | Render scraped data into a DataFrame (using Pandas) . | Format (or wrangle) the data into formats we can work with . | Present results in time series graph (using Seaborn) . | 1. Import packages and set configurations . First, let’s import some packages. We’ll use BeautifulSoup for web scraping, pandas for data analysis, and then seaborn for plotting. . # Import the packages we&#39;ll use for our analysis import datetime import time import requests from bs4 import BeautifulSoup import pandas as pd import seaborn as sns import matplotlib.pyplot as plt . Then we set the plotting configuration. I really like the “fivethirtyeight” stylesheet which generates plots in the style used by fivethirtyeight.com. . # Use line magic function to enable matplotlib to work interactively with iPython %matplotlib inline %pylab inline # Set style to fivethirtyeight to create clean and clear looking graphs plt.style.use(&#39;fivethirtyeight&#39;) # Define a dictionary containing default plotting configurations params = {&#39;legend.fontsize&#39;: &#39;small&#39;, &#39;figure.figsize&#39;: (12, 4.5), &#39;axes.labelsize&#39;: &#39;small&#39;, &#39;axes.titlesize&#39;:&#39;medium&#39;, &#39;xtick.labelsize&#39;:&#39;small&#39;, &#39;ytick.labelsize&#39;:&#39;small&#39;} pylab.rcParams.update(params) . Populating the interactive namespace from numpy and matplotlib . BASE_URL = &quot;http://www.svp100.co.uk/results-&quot; YEAR = 2017 . 2. Generate unformatted table of race data . def df_builder(base_url=BASE_URL, year=YEAR): &quot;&quot;&quot; This function returns a pandas DataFrame which contain data scraped from the race website. The data is unformatted. Attributes: -- base_url: the url which contains race data in HTML year: the year for we would like data &quot;&quot;&quot; # Scrape the data from the race website url = base_url + str(year) r = requests.get(url).text soup = BeautifulSoup(r, &#39;lxml&#39;) # Find tables from the html rows = soup.find_all(&#39;tr&#39;)[1:] # Collect and format column names for the dataframe column_html = soup.find_all(&#39;th&#39;)[:] columns = [i.contents[0].lower().replace(&quot;/&quot;,&quot;&quot;).replace(&quot; &quot;, &quot;_&quot;) for i in column_html if i.contents[0]] # Build a dataframe data = [] for line in rows: row = line.find_all(&#39;td&#39;) row_list = [] for counter, value in enumerate(row): row_list.append(row[counter].string) data.append(row_list) return pd.DataFrame(data, columns=columns).drop(columns = [&quot;name&quot;, &quot;club&quot;]).set_index(&quot;position&quot;) . unformatted_df = df_builder(BASE_URL, YEAR) . unformatted_df.tail(2) . bib mf start cp1 cp2 cp3 cp4 cp5 cp6 finish total_time . position . 91 162 | Female | 07:00:00 | 09:51:33 | DNF | None | None | None | None | None | None | . 92 7 | Male | 08:30:00 | 10:23:05 | DNF | None | None | None | None | None | None | . 3. Clean the table of race data . dt_cols = [&quot;start&quot;, &quot;cp1&quot;, &quot;cp2&quot;, &quot;cp3&quot;, &quot;cp4&quot;, &quot;cp5&quot;, &quot;cp6&quot;, &quot;finish&quot;, &quot;total_time&quot;] unformatted_df = unformatted_df.dropna() . for col in dt_cols: unformatted_df[col] = unformatted_df[col].apply(lambda x: pd.to_datetime(&quot;2017-08-08 &quot; + str(x))) . unformatted_df[&quot;time2cp1&quot;] = unformatted_df.cp1 - unformatted_df.start . unformatted_df . bib mf start cp1 cp2 cp3 cp4 cp5 cp6 finish total_time time2cp1 . position . 1 19 | Male | 2017-08-08 08:30:00 | 2017-08-08 09:58:30 | 2017-08-08 11:26:51 | 2017-08-08 12:58:00 | 2017-08-08 14:34:00 | 2017-08-08 15:41:00 | 2017-08-08 17:04:49 | 2017-08-08 17:54:10 | 2017-08-08 09:24:10 | 0 days 01:28:30 | . 2 20 | Male | 2017-08-08 08:30:00 | 2017-08-08 09:56:03 | 2017-08-08 11:22:10 | 2017-08-08 13:20:00 | 2017-08-08 15:14:00 | 2017-08-08 16:31:00 | 2017-08-08 18:13:51 | 2017-08-08 19:09:10 | 2017-08-08 10:39:10 | 0 days 01:26:03 | . 3 13 | Female | 2017-08-08 08:30:00 | 2017-08-08 10:14:44 | 2017-08-08 12:01:06 | 2017-08-08 13:50:00 | 2017-08-08 15:42:00 | 2017-08-08 16:56:00 | 2017-08-08 18:33:49 | 2017-08-08 19:30:55 | 2017-08-08 11:00:55 | 0 days 01:44:44 | . 4 8 | Male | 2017-08-08 08:30:00 | 2017-08-08 10:15:26 | 2017-08-08 12:08:01 | 2017-08-08 13:52:00 | 2017-08-08 15:52:00 | 2017-08-08 17:12:00 | 2017-08-08 18:53:46 | 2017-08-08 19:53:37 | 2017-08-08 11:23:37 | 0 days 01:45:26 | . 5 143 | Male | 2017-08-08 07:00:00 | 2017-08-08 08:49:35 | 2017-08-08 10:44:27 | 2017-08-08 12:33:00 | 2017-08-08 14:41:00 | 2017-08-08 16:02:00 | 2017-08-08 17:40:23 | 2017-08-08 18:36:58 | 2017-08-08 11:36:58 | 0 days 01:49:35 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 63 186 | Female | 2017-08-08 07:00:00 | 2017-08-08 09:15:33 | 2017-08-08 11:53:05 | 2017-08-08 14:17:00 | 2017-08-08 17:03:00 | 2017-08-08 18:56:00 | 2017-08-08 21:01:02 | 2017-08-08 22:21:22 | 2017-08-08 15:21:22 | 0 days 02:15:33 | . 64 120 | Male | 2017-08-08 07:00:00 | 2017-08-08 09:15:41 | 2017-08-08 11:53:00 | 2017-08-08 14:17:00 | 2017-08-08 17:03:00 | 2017-08-08 18:56:00 | 2017-08-08 21:01:04 | 2017-08-08 22:21:22 | 2017-08-08 15:21:22 | 0 days 02:15:41 | . 65 104 | Male | 2017-08-08 07:00:00 | 2017-08-08 09:15:30 | 2017-08-08 11:53:08 | 2017-08-08 14:17:00 | 2017-08-08 17:03:00 | 2017-08-08 18:56:00 | 2017-08-08 21:01:13 | 2017-08-08 22:21:22 | 2017-08-08 15:21:22 | 0 days 02:15:30 | . 66 121 | Female | 2017-08-08 07:00:00 | 2017-08-08 09:14:56 | 2017-08-08 11:41:59 | 2017-08-08 14:10:00 | 2017-08-08 16:54:00 | 2017-08-08 18:41:00 | 2017-08-08 21:00:25 | 2017-08-08 22:27:51 | 2017-08-08 15:27:51 | 0 days 02:14:56 | . 67 154 | Male | 2017-08-08 07:00:00 | 2017-08-08 09:14:43 | 2017-08-08 11:42:09 | 2017-08-08 14:10:00 | 2017-08-08 16:57:00 | 2017-08-08 18:41:00 | 2017-08-08 21:00:58 | 2017-08-08 22:27:51 | 2017-08-08 15:27:51 | 0 days 02:14:43 | . 67 rows × 12 columns . unformatted_df.cp3 = unformatted_df.cp3.apply(lambda x: str(x)) unformatted_df.cp3 = pd.to_datetime(unformatted_df.cp3) . unformatted_df.cp3 . position 1 2022-09-11 12:58:00 2 2022-09-11 13:20:00 3 2022-09-11 13:50:00 4 2022-09-11 13:52:00 5 2022-09-11 12:33:00 ... 63 2022-09-11 14:17:00 64 2022-09-11 14:17:00 65 2022-09-11 14:17:00 66 2022-09-11 14:10:00 67 2022-09-11 14:10:00 Name: cp3, Length: 67, dtype: datetime64[ns] . Create class for scraping and organising data . # Define a class Results for creating Pandas dataframe objects of scrapped data from race results website class raceResults(): &quot;&quot;&quot; This class returns pandas DataFrame objects which contain data scraped from the race website. Attributes: -- base_url: the url which contains race data in HTML year: the year for we would like data columns: the column headers for data to be scraped check_points: column headers used to calculate time between checkpoints &quot;&quot;&quot; def __init__(self, base_url, year, columns, check_points): self.base_url = base_url self.year = year self.columns = columns self.check_points = check_points def basic_table(self): url = base_url + str(self.year) r = requests.get(url).text soup = BeautifulSoup(r, &#39;lxml&#39;) lines = soup.find_all(&#39;tr&#39;)[1:] data = [] for line in lines: row = line.find_all(&#39;td&#39;) row_list = [] for counter, value in enumerate(row): row_list.append(row[counter].string) data.append(row_list) return pd.DataFrame(data, columns = columns).set_index(columns[1]) def df_results(self): df_results = self.basic_table() total = [] for i in df_results[&quot;total&quot;]: if i is not None: total.append(str(i)) else: total.append(0) df_results[&quot;total&quot;] = total def str2_min(x): ftr = [3600,60,1] if not x == 0: total_seconds = sum([a*b for a,b in zip(ftr, map(int,x.split(&#39;:&#39;)))]) return round((total_seconds / 60),2) df_results[&#39;total_min&#39;] = df_results[&#39;total&#39;].map(str2_min) df_results[&quot;average_min&quot;] = round(df_results[&quot;total_min&quot;].mean(), 2) df_results[&quot;start&quot;] = datetime.datetime(2017, 8, 12, 7, 0 ,0) cps = self.check_points def checkpoint2_datetime(cp): df_results[cp] = pd.to_datetime(df_results[cp], format = &quot;%H:%M:%S&quot;, errors=&quot;coerce&quot;) df_results[cp] = df_results[cp].apply(lambda dt: dt.replace(year = 2017, month = 8, day=12)) return df_results[cp] for i in cps: df_results[i] = checkpoint2_datetime(i) df_results[&quot;time2cp1&quot;] = df_results[&quot;cp1&quot;] - df_results[&quot;start&quot;] df_results[&quot;time2cp2&quot;] = df_results[&quot;cp2&quot;] - df_results[&quot;cp1&quot;] df_results[&quot;time2cp3&quot;] = df_results[&quot;cp3&quot;] - df_results[&quot;cp2&quot;] df_results[&quot;time2cp4&quot;] = df_results[&quot;cp4&quot;] - df_results[&quot;cp3&quot;] df_results[&quot;time2cp5&quot;] = df_results[&quot;cp5&quot;] - df_results[&quot;cp4&quot;] df_results[&quot;time2cp6&quot;] = df_results[&quot;cp6&quot;] - df_results[&quot;cp5&quot;] df_results[&quot;time2end&quot;] = df_results[&quot;finish&quot;] - df_results[&quot;cp6&quot;] return df_results def top_runners(self, x = 10): df_top = self.df_results()[:x] return df_top def target_runners(self, runner): df_runner = self.df_results().loc[runner] df_runner = pd.DataFrame(df_runner) return df_runner . # Next define a standalone function for creating averages from the Results() objects def average_pace(df): df = pd.DataFrame(df) convert_km = 1.60934 cp = [&quot;time2cp1&quot;, &quot;time2cp2&quot;, &quot;time2cp3&quot;, &quot;time2cp4&quot;, &quot;time2cp5&quot;, &quot;time2cp6&quot;, &quot;time2end&quot;] cp_miles = [12, 23, 33, 44, 50, 58.5, 63] cp_miles_s = [12,11,10,11,6,8.5,4.5] cp_distances = pd.DataFrame({&quot;cp_miles&quot;: cp_miles, &quot;cp_miles_s&quot;: cp_miles_s}, index = cp) cp_distances[&quot;cp_km&quot;] = cp_distances[&quot;cp_miles&quot;] * convert_km cp_distances[&quot;cp_km_s&quot;] = cp_distances[&quot;cp_miles_s&quot;] * convert_km df_time2cp = pd.DataFrame(df, columns= cp) df_averages = {} for i in cp: df_averages[str(i)] = df_time2cp[str(i)].mean() df_averages = pd.Series(df_averages, name = &quot;2017&quot;) df_averages = pd.DataFrame(df_averages) df_averages = (df_averages.join(cp_distances)) df_averages[&quot;2017_min&quot;] = [(i.total_seconds()/60) for i in df_averages[&quot;2017&quot;]] df_averages[&quot;min_km&quot;] = df_averages[&quot;2017_min&quot;]/df_averages[&quot;cp_km_s&quot;] return df_averages . Define some variables we will pass to our class . # Race website URL: base_url = r&#39;http://www.svp100.co.uk/results-&#39; # Column headers for the DataFrame scraped directly from the website: columns = [&quot;pos&quot;, &quot;name&quot;, &quot;bib&quot;, &quot;gender&quot;, &quot;start&quot;, &quot;club&quot;, &quot;cp1&quot;, &quot;cp2&quot;, &quot;cp3&quot;, &quot;cp4&quot;, &quot;cp5&quot;, &quot;cp6&quot;, &quot;finish&quot;, &quot;total&quot;] # List of new columns we&#39;ll add to the DataFrame for our analysis check_points = [&quot;cp1&quot;,&quot;cp2&quot;,&quot;cp3&quot;,&quot;cp4&quot;,&quot;cp5&quot;,&quot;cp6&quot;,&quot;finish&quot;] . Initialize a Results() object with results from 2017 race¶ . results = raceResults(base_url, 2017, columns, check_points) all_runners = results.df_results() all_runners = average_pace(all_runners) . top_3 = results.top_runners(10) top_3 = average_pace(top_3) . me = results.target_runners(&quot;Stephen Lemasney&quot;) . plots = all_runners.join(top_3, lsuffix = &quot;_all&quot;, rsuffix = &quot;_t3&quot;) plots = plots.join(me, rsuffix=&quot;_me&quot; ) plots[&quot;2017_me&quot;] = [(i.total_seconds()/60) for i in plots[&quot;Stephen Lemasney&quot;]] plots[&quot;min_km_me&quot;] = plots[&quot;2017_me&quot;]/plots[&quot;cp_km_s_all&quot;] plots = plots.rename(columns = {&quot;min_km_all&quot;:&quot;All Runners&quot;,&quot;min_km_t3&quot;:&quot;Top 10&quot;,&quot;min_km_me&quot;:&quot;Me&quot;}) . Plot the results using “FiveThirtyEight” styling . plots.plot(y = [&quot;All Runners&quot;,&quot;Top 10&quot;,&quot;Me&quot;], x = &quot;cp_km_all&quot;, figsize=(12,7)) plt.title(&#39;Average pace of runners (minutes per km)&#39;) plt.ylabel(&#39;Minutes per km&#39;, fontsize=&quot;small&quot;) plt.xlabel(&#39;Kilometers&#39;) plt.show() . .",
            "url": "https://fastpages.fast.ai/tutorials/markdown/2018/03/02/svp.html",
            "relUrl": "/markdown/2018/03/02/svp.html",
            "date": " • Mar 2, 2018"
        }
        
    
  
    
        ,"post4": {
            "title": "Find all Tuesdays",
            "content": "In this tutorial we look at two ways to solve the following problem: . Count the number of Tuesday between 1st of January 2000 and 31st of December 2020 . First, we find the answer using the very helpful Datetime package. This package does most of the heavy lifting for us. Then, for a bit of fun, we try and find the same solution using Python&#39;s default data types only. . 1. With the datetime package . Start by importing the datetime and timedelta class. . from datetime import datetime, timedelta . Then write a function which takes two paraters, start_year and end_year, which returns the number of Tuesdays between these years. There is an assumption that start_year starts on 1st day of the year, and end_year ends on the last day of that year. . def count_tuesdays(start_year, end_year): &quot;&quot;&quot; Returns the number of Tuesaday between two dates. Parameters: start_year (int): The starting year end_year (int): The end year Returns: count_tuesdays(int): The number of Tuesdays between start_year and end_year &quot;&quot;&quot; # 1. Find the number of days between start and end year datetime_range = datetime(year=end_year, month=1, day=1) - datetime(year=start_year, month=12, day=31) # 2. Build a list of Datetimes for this range date_range = [datetime(year=start_year, month=1, day=1) + timedelta(days=x) for x in range(datetime_range.days)] # 3. Count the number of Tuesdays in this range count_tuesdays = len([i for i in date_range if i.isoweekday() == 2]) return count_tuesdays . count_tuesdays(2000, 2021) . 1044 . 2. Using default Python data structures . Next, lets make it a little harder to solve. Lets find the same result, this time only using Python&#39;s default data structures. In order words, we cannot rely on the datetime package. . First, we create a simple Date object which has the following attributes: . year | month | day | is_leap | day_of_week | day_of_weel_decode | There is nothing too complicated here. We assign some validation on the attributes. For example, the days cannot be greater than 31 and months cannot be greater than 12. . class Date(): def __init__(self, year, month, day, day_of_week): self.year = year self.is_leap = self._is_leap(self.year) self.month = month self.day = day self.day_of_week = day_of_week self.day_of_week_decode = self._day_of_week_decode() @property def day(self): return self._day @day.setter def day(self, value): if (value &gt; 31): raise Exception(&quot;Days cannot be greater than 31&quot;) if (self.month in [9, 4, 6, 11] and value &gt; 31): raise Exception(f&quot;Days cannot be greater than 30 for month {self.month}&quot;) if (self.month == 2): if (self.is_leap == True and value &gt; 29): raise Exception(f&quot;Days must be 29 or less for a leap year Febuary&quot;) if (self.is_leap == False and value &gt; 28): raise Exception(f&quot;Days must be 28 or less for a non-leap year Febuary&quot;) self._day = value @property def month(self): return self._month @month.setter def month(self, value): if (value &gt; 12): raise Exception(&quot;Month cannot be greater than 12&quot;) self._month = value @property def year(self): return self._year @year.setter def year(self, value): self._year = value @property def day_of_week(self): return self._day_of_week @day_of_week.setter def day_of_week(self, value): self._day_of_week = value def _is_leap(self, year): if (year % 4 == 0) &amp; (year % 100 != 0): return True if (year % 100 == 0) &amp; (year % 400 == 0): return True return False def _day_of_week_decode(self): decodes = { 1: &quot;Mon&quot;, 2: &quot;Tue&quot;, 3: &quot;Wed&quot;, 4: &quot;Thu&quot;, 5: &quot;Fri&quot;, 6: &quot;Sat&quot;, 7: &quot;Sun&quot; } return decodes[self.day_of_week] def __str__(self): return f&quot;{self.year}-{self.month}-{self.day}&quot; def __repr__(self): return f&quot;Date({self.year}-{self.month}-{self.day}, {self.day_of_week_decode})&quot; . Let&#39;s build a sample date object to check everything looks ok. We&#39;ll create a Date for Tuesday 29th of Febuary 2000. . Date(2000, 2, 29, 2) . Date(2000-2-29, Tue) . try: sample_date = Date(2001, 2, 29, 2) except Exception as e: print(e) . Days must be 28 or less for a non-leap year Febuary . Next, let&#39;s build up a range of dates. First we need a generator which will return a weekday label (1 to 7) for each date in our range. We know that the 1st of January is a saturday so we will build our iterable from that point. . class DateRange(): def __init__(self, start_year, end_year, start_day_of_week): self.start_year = start_year self.end_year = end_year self.start_day_of_week = start_day_of_week self.range = self.build_range(start_year, end_year, start_day_of_week) def _days_of_week(self, starting_day): days_of_week = list(range(1,8)) days_of_week = days_of_week[(starting_day-1):] + days_of_week[:(starting_day-1)] while True: for n in days_of_week: yield(n) def _is_leap(self, year): if (year % 4 == 0) &amp; (year % 100 != 0): return True if (year % 100 == 0) &amp; (year % 400 == 0): return True return False def build_range(self, start_year, end_year, start_day_of_week): day_of_week_iterator = self._days_of_week(start_day_of_week) date_range = [] for year in range(start_year, end_year+1): for month in range(1, 13): if month in [9, 4, 6, 11]: day_count = 30 elif (month == 2 and self._is_leap(year)): day_count = 29 elif (month == 2 and self._is_leap(year) is False): day_count = 28 else: day_count = 31 days_in_month = [Date(year, month, i, next(day_of_week_iterator)) for i in range(1, day_count+1)] date_range.extend(days_in_month) return date_range . date_range = DateRange(2000, 2019, 6).range count_tuesdays = len([i for i in date_range if i.day_of_week == 2]) count_tuesdays . 1044 .",
            "url": "https://fastpages.fast.ai/tutorials/2018/03/01/count-tuesdays.html",
            "relUrl": "/2018/03/01/count-tuesdays.html",
            "date": " • Mar 1, 2018"
        }
        
    
  
    
        ,"post5": {
            "title": "Copying objects in Python",
            "content": "In this tutorial we compare a shallow versus deep copy in Python using the inbuilt copy module. . from copy import copy . 1. Assignment . First we create a list called foo_list which has three items: two ints and one list of ints. We run the in-built id function to check the address of the list object in memory. . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930710693248 . Next we create a second variable called foo_list_two which is assigned to foo_list. We can see that both variables point to the same object in memory. . foo_list_two = foo_list # Check the two variables point to the same object id(foo_list) == id(foo_list_two) . True . foo_list[0] = 11 # Check the second list foo_list_two . [11, 2, [3, 4]] . %reset -f . 3. Shallow copy . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930709728704 . foo_list_two = foo_list.copy() # Check the two variables point to the same object id(foo_list) == id(foo_list_two) . False . foo_list[2][0] = 11 # Check the second list foo_list_two . [1, 2, [11, 4]] . 3. Deep copy . A deep copy creates a new object and recursively adds the copies of nested objects present in the original elements. . from copy import deepcopy . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930709811328 . foo_list_two = deepcopy(foo_list) # Check the two variables point to different objects id(foo_list) == id(foo_list_two) . False . foo_list[2][0] = 11 # Check that the deep copied list does not update print(foo_list) print(foo_list_two) . [11, 2, [11, 4]] [1, 2, [3, 4]] . foo_list[2][0] = 22 . print(foo_list) print(foo_list_two) . [11, 2, [22, 4]] [1, 2, [3, 4]] .",
            "url": "https://fastpages.fast.ai/tutorials/2018/01/02/copying-objects.html",
            "relUrl": "/2018/01/02/copying-objects.html",
            "date": " • Jan 2, 2018"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://fastpages.fast.ai/tutorials/markdown/2018/01/01/test-markdown-post.html",
            "relUrl": "/markdown/2018/01/01/test-markdown-post.html",
            "date": " • Jan 1, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi There! I am Stephen Lemasney. I work in FinTech as a Sales Engineer. In this blog I share some Python and data tutorials. .",
          "url": "https://fastpages.fast.ai/tutorials/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://fastpages.fast.ai/tutorials/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}