{
  
    
        "post0": {
            "title": "Tutorial - Testing the match case statements",
            "content": "1. What is the match-case statement? . On the surface it looks very simliar to an if-else statement. You provide some conditions, and the statement retuns a value if those conditions are met. For example, here we have a match-case to match the London TFL tube to that line&#39;s official colour. . def find_tube(tube_line_colour): match tube_line_colour: case &quot;black&quot;: return &quot;northern&quot; case &quot;red&quot; | &quot;orange&quot;: return &quot;central&quot; case _: return &quot;unknown&quot; . display(find_tube(&quot;red&quot;)) display(find_tube(&quot;darkgreen&quot;)) . &#39;central&#39; . &#39;unknown&#39; . We could also implement the same logic using an if-else statement: . def find_tube(tube_line_colour): if tube_line_colour == &quot;black&quot;: return &quot;northern&quot; elif tube_line_colour == &quot;red&quot; or tube_line_colour == &quot;orange&quot;: return &quot;central&quot; else: return &quot;unknown&quot; . display(find_tube(&quot;red&quot;)) display(find_tube(&quot;darkgreen&quot;)) . &#39;central&#39; . &#39;unknown&#39; . 2. What features does it have? .",
            "url": "https://fastpages.fast.ai/tutorials/2022/06/27/match-case.html",
            "relUrl": "/2022/06/27/match-case.html",
            "date": " • Jun 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Measuring Equity Risk",
            "content": "Import packages and setup configurations . import pandas as pd import quandl import datetime import matplotlib.pyplot as plt import seaborn as sns import os from sklearn import linear_model plt.style.use(&#39;fivethirtyeight&#39;) from statsmodels.formula.api import ols # Use Python&#39;s &quot;magic&quot; commands since we want to see the graphs within this notebook %matplotlib inline %pylab inline pylab.rcParams[&quot;figure.figsize&quot;] = (8,6) . Populating the interactive namespace from numpy and matplotlib . directory = os.getcwd() + &quot;/data/&quot; # CSV file contained within local directory .",
            "url": "https://fastpages.fast.ai/tutorials/2018/03/03/measure-equity-risk.html",
            "relUrl": "/2018/03/03/measure-equity-risk.html",
            "date": " • Mar 3, 2018"
        }
        
    
  
    
        ,"post2": {
            "title": "SVP100 - Hitting The Wall",
            "content": "SVP100 - Hitting The Wall . In August of 2017 I ran the SVP100. This is a 100KM trail running race starting in Newmarket (Suffolk, UK) and ending in Manning Tree (Essex, UK). In regular distance marathons, its widely believed runners “hit the wall” at around 30KM mark (or 70% through the race). In this notebook, I want to see if the same holds true over a 100KM distance. . From a high level, the code below performs the following: . Scrape results data from the race website (using Beautiful Soup) . | Render scraped data into a DataFrame (using Pandas) . | Format (or wrangle) the data into formats we can work with . | Present results in time series graph (using Seaborn) . | 1. Import packages and set configurations . First, let’s import some packages. We’ll use BeautifulSoup for web scraping, pandas for data analysis, and then seaborn for plotting. . # Import the packages we&#39;ll use for our analysis import datetime import time import requests from bs4 import BeautifulSoup import pandas as pd import seaborn as sns import matplotlib.pyplot as plt . Then we set the plotting configuration. I really like the “fivethirtyeight” stylesheet which generates plots in the style used by fivethirtyeight.com. . # Use line magic function to enable matplotlib to work interactively with iPython %matplotlib inline %pylab inline # Set style to fivethirtyeight to create clean and clear looking graphs plt.style.use(&#39;fivethirtyeight&#39;) # Define a dictionary containing default plotting configurations params = {&#39;legend.fontsize&#39;: &#39;small&#39;, &#39;figure.figsize&#39;: (12, 4.5), &#39;axes.labelsize&#39;: &#39;small&#39;, &#39;axes.titlesize&#39;:&#39;medium&#39;, &#39;xtick.labelsize&#39;:&#39;small&#39;, &#39;ytick.labelsize&#39;:&#39;small&#39;} pylab.rcParams.update(params) . Populating the interactive namespace from numpy and matplotlib . BASE_URL = &quot;http://www.svp100.co.uk/results-&quot; YEAR = 2017 . 2. Generate unformatted table of race data . def df_builder(base_url=BASE_URL, year=YEAR): &quot;&quot;&quot; This function returns a pandas DataFrame which contain data scraped from the race website. The data is unformatted. Attributes: -- base_url: the url which contains race data in HTML year: the year for we would like data &quot;&quot;&quot; # Scrape the data from the race website url = base_url + str(year) r = requests.get(url).text soup = BeautifulSoup(r, &#39;lxml&#39;) # Find tables from the html rows = soup.find_all(&#39;tr&#39;)[1:] # Collect and format column names for the dataframe column_html = soup.find_all(&#39;th&#39;)[:] columns = [i.contents[0].lower().replace(&quot;/&quot;,&quot;&quot;).replace(&quot; &quot;, &quot;_&quot;) for i in column_html if i.contents[0]] # Build a dataframe data = [] for line in rows: row = line.find_all(&#39;td&#39;) row_list = [] for counter, value in enumerate(row): row_list.append(row[counter].string) data.append(row_list) return pd.DataFrame(data, columns=columns).drop(columns = [&quot;name&quot;, &quot;club&quot;]).set_index(&quot;position&quot;) . unformatted_df = df_builder(BASE_URL, YEAR) . unformatted_df.tail(2) . bib mf start cp1 cp2 cp3 cp4 cp5 cp6 finish total_time . position . 91 162 | Female | 07:00:00 | 09:51:33 | DNF | None | None | None | None | None | None | . 92 7 | Male | 08:30:00 | 10:23:05 | DNF | None | None | None | None | None | None | . 3. Clean the table of race data . dt_cols = [&quot;start&quot;, &quot;cp1&quot;, &quot;cp2&quot;, &quot;cp3&quot;, &quot;cp4&quot;, &quot;cp5&quot;, &quot;cp6&quot;, &quot;finish&quot;, &quot;total_time&quot;] unformatted_df = unformatted_df.dropna() . for col in dt_cols: unformatted_df[col] = unformatted_df[col].apply(lambda x: pd.to_datetime(&quot;2017-08-08 &quot; + str(x))) . unformatted_df[&quot;time2cp1&quot;] = unformatted_df.cp1 - unformatted_df.start . unformatted_df . bib mf start cp1 cp2 cp3 cp4 cp5 cp6 finish total_time time2cp1 . position . 1 19 | Male | 2017-08-08 08:30:00 | 2017-08-08 09:58:30 | 2017-08-08 11:26:51 | 2017-08-08 12:58:00 | 2017-08-08 14:34:00 | 2017-08-08 15:41:00 | 2017-08-08 17:04:49 | 2017-08-08 17:54:10 | 2017-08-08 09:24:10 | 0 days 01:28:30 | . 2 20 | Male | 2017-08-08 08:30:00 | 2017-08-08 09:56:03 | 2017-08-08 11:22:10 | 2017-08-08 13:20:00 | 2017-08-08 15:14:00 | 2017-08-08 16:31:00 | 2017-08-08 18:13:51 | 2017-08-08 19:09:10 | 2017-08-08 10:39:10 | 0 days 01:26:03 | . 3 13 | Female | 2017-08-08 08:30:00 | 2017-08-08 10:14:44 | 2017-08-08 12:01:06 | 2017-08-08 13:50:00 | 2017-08-08 15:42:00 | 2017-08-08 16:56:00 | 2017-08-08 18:33:49 | 2017-08-08 19:30:55 | 2017-08-08 11:00:55 | 0 days 01:44:44 | . 4 8 | Male | 2017-08-08 08:30:00 | 2017-08-08 10:15:26 | 2017-08-08 12:08:01 | 2017-08-08 13:52:00 | 2017-08-08 15:52:00 | 2017-08-08 17:12:00 | 2017-08-08 18:53:46 | 2017-08-08 19:53:37 | 2017-08-08 11:23:37 | 0 days 01:45:26 | . 5 143 | Male | 2017-08-08 07:00:00 | 2017-08-08 08:49:35 | 2017-08-08 10:44:27 | 2017-08-08 12:33:00 | 2017-08-08 14:41:00 | 2017-08-08 16:02:00 | 2017-08-08 17:40:23 | 2017-08-08 18:36:58 | 2017-08-08 11:36:58 | 0 days 01:49:35 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 63 186 | Female | 2017-08-08 07:00:00 | 2017-08-08 09:15:33 | 2017-08-08 11:53:05 | 2017-08-08 14:17:00 | 2017-08-08 17:03:00 | 2017-08-08 18:56:00 | 2017-08-08 21:01:02 | 2017-08-08 22:21:22 | 2017-08-08 15:21:22 | 0 days 02:15:33 | . 64 120 | Male | 2017-08-08 07:00:00 | 2017-08-08 09:15:41 | 2017-08-08 11:53:00 | 2017-08-08 14:17:00 | 2017-08-08 17:03:00 | 2017-08-08 18:56:00 | 2017-08-08 21:01:04 | 2017-08-08 22:21:22 | 2017-08-08 15:21:22 | 0 days 02:15:41 | . 65 104 | Male | 2017-08-08 07:00:00 | 2017-08-08 09:15:30 | 2017-08-08 11:53:08 | 2017-08-08 14:17:00 | 2017-08-08 17:03:00 | 2017-08-08 18:56:00 | 2017-08-08 21:01:13 | 2017-08-08 22:21:22 | 2017-08-08 15:21:22 | 0 days 02:15:30 | . 66 121 | Female | 2017-08-08 07:00:00 | 2017-08-08 09:14:56 | 2017-08-08 11:41:59 | 2017-08-08 14:10:00 | 2017-08-08 16:54:00 | 2017-08-08 18:41:00 | 2017-08-08 21:00:25 | 2017-08-08 22:27:51 | 2017-08-08 15:27:51 | 0 days 02:14:56 | . 67 154 | Male | 2017-08-08 07:00:00 | 2017-08-08 09:14:43 | 2017-08-08 11:42:09 | 2017-08-08 14:10:00 | 2017-08-08 16:57:00 | 2017-08-08 18:41:00 | 2017-08-08 21:00:58 | 2017-08-08 22:27:51 | 2017-08-08 15:27:51 | 0 days 02:14:43 | . 67 rows × 12 columns . unformatted_df.cp3 = unformatted_df.cp3.apply(lambda x: str(x)) unformatted_df.cp3 = pd.to_datetime(unformatted_df.cp3) . unformatted_df.cp3 . position 1 2022-09-11 12:58:00 2 2022-09-11 13:20:00 3 2022-09-11 13:50:00 4 2022-09-11 13:52:00 5 2022-09-11 12:33:00 ... 63 2022-09-11 14:17:00 64 2022-09-11 14:17:00 65 2022-09-11 14:17:00 66 2022-09-11 14:10:00 67 2022-09-11 14:10:00 Name: cp3, Length: 67, dtype: datetime64[ns] . Create class for scraping and organising data . # Define a class Results for creating Pandas dataframe objects of scrapped data from race results website class raceResults(): &quot;&quot;&quot; This class returns pandas DataFrame objects which contain data scraped from the race website. Attributes: -- base_url: the url which contains race data in HTML year: the year for we would like data columns: the column headers for data to be scraped check_points: column headers used to calculate time between checkpoints &quot;&quot;&quot; def __init__(self, base_url, year, columns, check_points): self.base_url = base_url self.year = year self.columns = columns self.check_points = check_points def basic_table(self): url = base_url + str(self.year) r = requests.get(url).text soup = BeautifulSoup(r, &#39;lxml&#39;) lines = soup.find_all(&#39;tr&#39;)[1:] data = [] for line in lines: row = line.find_all(&#39;td&#39;) row_list = [] for counter, value in enumerate(row): row_list.append(row[counter].string) data.append(row_list) return pd.DataFrame(data, columns = columns).set_index(columns[1]) def df_results(self): df_results = self.basic_table() total = [] for i in df_results[&quot;total&quot;]: if i is not None: total.append(str(i)) else: total.append(0) df_results[&quot;total&quot;] = total def str2_min(x): ftr = [3600,60,1] if not x == 0: total_seconds = sum([a*b for a,b in zip(ftr, map(int,x.split(&#39;:&#39;)))]) return round((total_seconds / 60),2) df_results[&#39;total_min&#39;] = df_results[&#39;total&#39;].map(str2_min) df_results[&quot;average_min&quot;] = round(df_results[&quot;total_min&quot;].mean(), 2) df_results[&quot;start&quot;] = datetime.datetime(2017, 8, 12, 7, 0 ,0) cps = self.check_points def checkpoint2_datetime(cp): df_results[cp] = pd.to_datetime(df_results[cp], format = &quot;%H:%M:%S&quot;, errors=&quot;coerce&quot;) df_results[cp] = df_results[cp].apply(lambda dt: dt.replace(year = 2017, month = 8, day=12)) return df_results[cp] for i in cps: df_results[i] = checkpoint2_datetime(i) df_results[&quot;time2cp1&quot;] = df_results[&quot;cp1&quot;] - df_results[&quot;start&quot;] df_results[&quot;time2cp2&quot;] = df_results[&quot;cp2&quot;] - df_results[&quot;cp1&quot;] df_results[&quot;time2cp3&quot;] = df_results[&quot;cp3&quot;] - df_results[&quot;cp2&quot;] df_results[&quot;time2cp4&quot;] = df_results[&quot;cp4&quot;] - df_results[&quot;cp3&quot;] df_results[&quot;time2cp5&quot;] = df_results[&quot;cp5&quot;] - df_results[&quot;cp4&quot;] df_results[&quot;time2cp6&quot;] = df_results[&quot;cp6&quot;] - df_results[&quot;cp5&quot;] df_results[&quot;time2end&quot;] = df_results[&quot;finish&quot;] - df_results[&quot;cp6&quot;] return df_results def top_runners(self, x = 10): df_top = self.df_results()[:x] return df_top def target_runners(self, runner): df_runner = self.df_results().loc[runner] df_runner = pd.DataFrame(df_runner) return df_runner . # Next define a standalone function for creating averages from the Results() objects def average_pace(df): df = pd.DataFrame(df) convert_km = 1.60934 cp = [&quot;time2cp1&quot;, &quot;time2cp2&quot;, &quot;time2cp3&quot;, &quot;time2cp4&quot;, &quot;time2cp5&quot;, &quot;time2cp6&quot;, &quot;time2end&quot;] cp_miles = [12, 23, 33, 44, 50, 58.5, 63] cp_miles_s = [12,11,10,11,6,8.5,4.5] cp_distances = pd.DataFrame({&quot;cp_miles&quot;: cp_miles, &quot;cp_miles_s&quot;: cp_miles_s}, index = cp) cp_distances[&quot;cp_km&quot;] = cp_distances[&quot;cp_miles&quot;] * convert_km cp_distances[&quot;cp_km_s&quot;] = cp_distances[&quot;cp_miles_s&quot;] * convert_km df_time2cp = pd.DataFrame(df, columns= cp) df_averages = {} for i in cp: df_averages[str(i)] = df_time2cp[str(i)].mean() df_averages = pd.Series(df_averages, name = &quot;2017&quot;) df_averages = pd.DataFrame(df_averages) df_averages = (df_averages.join(cp_distances)) df_averages[&quot;2017_min&quot;] = [(i.total_seconds()/60) for i in df_averages[&quot;2017&quot;]] df_averages[&quot;min_km&quot;] = df_averages[&quot;2017_min&quot;]/df_averages[&quot;cp_km_s&quot;] return df_averages . Define some variables we will pass to our class . # Race website URL: base_url = r&#39;http://www.svp100.co.uk/results-&#39; # Column headers for the DataFrame scraped directly from the website: columns = [&quot;pos&quot;, &quot;name&quot;, &quot;bib&quot;, &quot;gender&quot;, &quot;start&quot;, &quot;club&quot;, &quot;cp1&quot;, &quot;cp2&quot;, &quot;cp3&quot;, &quot;cp4&quot;, &quot;cp5&quot;, &quot;cp6&quot;, &quot;finish&quot;, &quot;total&quot;] # List of new columns we&#39;ll add to the DataFrame for our analysis check_points = [&quot;cp1&quot;,&quot;cp2&quot;,&quot;cp3&quot;,&quot;cp4&quot;,&quot;cp5&quot;,&quot;cp6&quot;,&quot;finish&quot;] . Initialize a Results() object with results from 2017 race¶ . results = raceResults(base_url, 2017, columns, check_points) all_runners = results.df_results() all_runners = average_pace(all_runners) . top_3 = results.top_runners(10) top_3 = average_pace(top_3) . me = results.target_runners(&quot;Stephen Lemasney&quot;) . plots = all_runners.join(top_3, lsuffix = &quot;_all&quot;, rsuffix = &quot;_t3&quot;) plots = plots.join(me, rsuffix=&quot;_me&quot; ) plots[&quot;2017_me&quot;] = [(i.total_seconds()/60) for i in plots[&quot;Stephen Lemasney&quot;]] plots[&quot;min_km_me&quot;] = plots[&quot;2017_me&quot;]/plots[&quot;cp_km_s_all&quot;] plots = plots.rename(columns = {&quot;min_km_all&quot;:&quot;All Runners&quot;,&quot;min_km_t3&quot;:&quot;Top 10&quot;,&quot;min_km_me&quot;:&quot;Me&quot;}) . Plot the results using “FiveThirtyEight” styling . plots.plot(y = [&quot;All Runners&quot;,&quot;Top 10&quot;,&quot;Me&quot;], x = &quot;cp_km_all&quot;, figsize=(12,7)) plt.title(&#39;Average pace of runners (minutes per km)&#39;) plt.ylabel(&#39;Minutes per km&#39;, fontsize=&quot;small&quot;) plt.xlabel(&#39;Kilometers&#39;) plt.show() . .",
            "url": "https://fastpages.fast.ai/tutorials/markdown/2018/03/02/svp.html",
            "relUrl": "/markdown/2018/03/02/svp.html",
            "date": " • Mar 2, 2018"
        }
        
    
  
    
        ,"post3": {
            "title": "Find all Tuesdays",
            "content": "1. With the datetime package . Start by importing the datetime and timedelta class. . from datetime import datetime, timedelta . Then write a function which takes two paraters, start_year and end_year, which returns the number of Tuesdays between these years. There is an assumption that start_year starts on 1st day of the year, and end_year ends on the last day of that year. . def count_tuesdays(start_year, end_year): &quot;&quot;&quot; Returns the number of Tuesaday between two dates. Parameters: start_year (int): The starting year end_year (int): The end year Returns: count_tuesdays(int): The number of Tuesdays between start_year and end_year &quot;&quot;&quot; # 1. Find the number of days between start and end year datetime_range = datetime(year=end_year, month=1, day=1) - datetime(year=start_year, month=12, day=31) # 2. Build a list of Datetimes for this range date_range = [datetime(year=start_year, month=1, day=1) + timedelta(days=x) for x in range(datetime_range.days)] # 3. Count the number of Tuesdays in this range count_tuesdays = len([i for i in date_range if i.isoweekday() == 2]) return count_tuesdays . count_tuesdays(2000, 2021) . 1044 . 2. Using default Python data structures . Next, lets make it a little harder to solve. Lets find the same result, this time only using Python&#39;s default data structures. In order words, we cannot rely on the datetime package. . First, we create a simple Date object which has the following attributes: . year | month | day | is_leap | day_of_week | day_of_weel_decode | There is nothing too complicated here. We assign some validation on the attributes. For example, the days cannot be greater than 31 and months cannot be greater than 12. . class Date(): def __init__(self, year, month, day, day_of_week): self.year = year self.is_leap = self._is_leap(self.year) self.month = month self.day = day self.day_of_week = day_of_week self.day_of_week_decode = self._day_of_week_decode() @property def day(self): return self._day @day.setter def day(self, value): if (value &gt; 31): raise Exception(&quot;Days cannot be greater than 31&quot;) if (self.month in [9, 4, 6, 11] and value &gt; 31): raise Exception(f&quot;Days cannot be greater than 30 for month {self.month}&quot;) if (self.month == 2): if (self.is_leap == True and value &gt; 29): raise Exception(f&quot;Days must be 29 or less for a leap year Febuary&quot;) if (self.is_leap == False and value &gt; 28): raise Exception(f&quot;Days must be 28 or less for a non-leap year Febuary&quot;) self._day = value @property def month(self): return self._month @month.setter def month(self, value): if (value &gt; 12): raise Exception(&quot;Month cannot be greater than 12&quot;) self._month = value @property def year(self): return self._year @year.setter def year(self, value): self._year = value @property def day_of_week(self): return self._day_of_week @day_of_week.setter def day_of_week(self, value): self._day_of_week = value def _is_leap(self, year): if (year % 4 == 0) &amp; (year % 100 != 0): return True if (year % 100 == 0) &amp; (year % 400 == 0): return True return False def _day_of_week_decode(self): decodes = { 1: &quot;Mon&quot;, 2: &quot;Tue&quot;, 3: &quot;Wed&quot;, 4: &quot;Thu&quot;, 5: &quot;Fri&quot;, 6: &quot;Sat&quot;, 7: &quot;Sun&quot; } return decodes[self.day_of_week] def __str__(self): return f&quot;{self.year}-{self.month}-{self.day}&quot; def __repr__(self): return f&quot;Date({self.year}-{self.month}-{self.day}, {self.day_of_week_decode})&quot; . Let&#39;s build a sample date object to check everything looks ok. We&#39;ll create a Date for Tuesday 29th of Febuary 2000. . Date(2000, 2, 29, 2) . Date(2000-2-29, Tue) . try: sample_date = Date(2001, 2, 29, 2) except Exception as e: print(e) . Days must be 28 or less for a non-leap year Febuary . Next, let&#39;s build up a range of dates. First we need a generator which will return a weekday label (1 to 7) for each date in our range. We know that the 1st of January is a saturday so we will build our iterable from that point. . class DateRange(): def __init__(self, start_year, end_year, start_day_of_week): self.start_year = start_year self.end_year = end_year self.start_day_of_week = start_day_of_week self.range = self.build_range(start_year, end_year, start_day_of_week) def _days_of_week(self, starting_day): days_of_week = list(range(1,8)) days_of_week = days_of_week[(starting_day-1):] + days_of_week[:(starting_day-1)] while True: for n in days_of_week: yield(n) def _is_leap(self, year): if (year % 4 == 0) &amp; (year % 100 != 0): return True if (year % 100 == 0) &amp; (year % 400 == 0): return True return False def build_range(self, start_year, end_year, start_day_of_week): day_of_week_iterator = self._days_of_week(start_day_of_week) date_range = [] for year in range(start_year, end_year+1): for month in range(1, 13): if month in [9, 4, 6, 11]: day_count = 30 elif (month == 2 and self._is_leap(year)): day_count = 29 elif (month == 2 and self._is_leap(year) is False): day_count = 28 else: day_count = 31 days_in_month = [Date(year, month, i, next(day_of_week_iterator)) for i in range(1, day_count+1)] date_range.extend(days_in_month) return date_range . date_range = DateRange(2000, 2019, 6).range count_tuesdays = len([i for i in date_range if i.day_of_week == 2]) count_tuesdays . 1044 .",
            "url": "https://fastpages.fast.ai/tutorials/2018/03/01/count-tuesdays.html",
            "relUrl": "/2018/03/01/count-tuesdays.html",
            "date": " • Mar 1, 2018"
        }
        
    
  
    
        ,"post4": {
            "title": "Copying objects in Python",
            "content": "In this tutorial we compare a shallow versus deep copy in Python using the inbuilt copy module. . from copy import copy . 1. Assignment . First we create a list called foo_list which has three items: two ints and one list of ints. We run the in-built id function to check the address of the list object in memory. . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930710693248 . Next we create a second variable called foo_list_two which is assigned to foo_list. We can see that both variables point to the same object in memory. . foo_list_two = foo_list # Check the two variables point to the same object id(foo_list) == id(foo_list_two) . True . foo_list[0] = 11 # Check the second list foo_list_two . [11, 2, [3, 4]] . %reset -f . 3. Shallow copy . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930709728704 . foo_list_two = foo_list.copy() # Check the two variables point to the same object id(foo_list) == id(foo_list_two) . False . foo_list[2][0] = 11 # Check the second list foo_list_two . [1, 2, [11, 4]] . 3. Deep copy . A deep copy creates a new object and recursively adds the copies of nested objects present in the original elements. . from copy import deepcopy . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930709811328 . foo_list_two = deepcopy(foo_list) # Check the two variables point to different objects id(foo_list) == id(foo_list_two) . False . foo_list[2][0] = 11 # Check that the deep copied list does not update print(foo_list) print(foo_list_two) . [11, 2, [11, 4]] [1, 2, [3, 4]] . foo_list[2][0] = 22 . print(foo_list) print(foo_list_two) . [11, 2, [22, 4]] [1, 2, [3, 4]] .",
            "url": "https://fastpages.fast.ai/tutorials/2018/01/20/copying-objects.html",
            "relUrl": "/2018/01/20/copying-objects.html",
            "date": " • Jan 20, 2018"
        }
        
    
  
    
        ,"post5": {
            "title": "Deploying a Python app with Docker (Part 1)",
            "content": "In this tutorial, we show how you can build and deploy a really simple Python app using Docker. To demonstrate, we&#39;ll create an API to return details of the TFL train lines in London. We&#39;ll use Flask to build the application. . Create a Flask app . First, create a python flask app which returns details about the TFL trains. This application serves a very basic API with details on London&#39;s TFL trains. . from flask import Flask, jsonify, request import sys import logging logging.basicConfig(level=logging.INFO) app = Flask(__name__) tasks = [ { &#39;id&#39;: 1, &#39;service&#39;: &#39;tube&#39;, &#39;line&#39;: &#39;northern&#39;, &#39;colour&#39;: &#39;black&#39; }, { &#39;id&#39;: 2, &#39;service&#39;: &#39;tube&#39;, &#39;line&#39;: &#39;circle&#39;, &#39;colour&#39;: &#39;red&#39; } ] def shutdown_server(): func = request.environ.get(&#39;werkzeug.server.shutdown&#39;) if func is None: raise RuntimeError(&#39;Not running with the Werkzeug Server&#39;) func() @app.route(&#39;/trains&#39;, methods=[&#39;GET&#39;]) def get_tasks(): return jsonify({&#39;tasks&#39;: tasks}) @app.route(&#39;/&#39;) def hello_world(): return &#39;Welcome to trains API&#39; @app.route(&#39;/exit&#39;) def exit(): message = logging.info(&quot;Stopping application&quot;) shutdown_server() print(&quot;The Flask server has been shutdown.&quot;) if __name__ == &#39;__main__&#39;: app.run(debug=True, host=&#39;0.0.0.0&#39;) . Run a quick &#39;hello world&#39; type test . import requests url = &quot;http://192.168.1.74:5000/&quot; response = requests.get(url) response_code = response.status_code response_text = requests.get(url).text display(response_code) display(response_text) . 200 . &#39;Welcome to trains API&#39; . Setup the Dockerfile . Next, we want to package the application into a container using a Dockerfile. The finished Dockerfile will look as follows: . FROM python:3.7-alpine COPY . /app WORKDIR /app RUN pip install -r requirements.txt EXPOSE 5000 CMD [&quot;python&quot;, &quot;app.py&quot;] . Deconstruct the Dockerfile . Let&#39;s break down each line in turn to describe what is happening... . In the first line we declare a parent image which is the image our own image is based on. Each subsequent declaration in the Dockerfile modifies this image. In our example, we use a version of Alpine Linux as our base image. Alpine Linux is a lightweight Linux distribution which makes it ideal for our container. . FROM python:3.7-alpine . Next we copy all of the files from the current host directory into the container&#39;s app directory. . COPY . /app . We change our working directory to the app directory. And then we tell Docker to install the Python packages needed for the app.py . WORKDIR /app RUN pip install -r requirements.txt . Next we tell the container to listen on a specific network port at runtime. The default is TCP but you can also specify UDP. Note that the EXPOSE instruction does not actually publish the port. This instruction is there for documentation purposes. To actually publish the port, you need to use the -p flag on the docker run command. . EXPOSE 5000 . Finally, we run the app: . CMD [&quot;python&quot;, &quot;app.py&quot;] . Run the docker container locally . You might want to run the Dockerfile on your own machine to verify that it is working correctly. To do that, we docker build and then docker run: . You can build the Dockerfile as follows. The -t or tag allows you to tag the image with a name. . docker build -t slemasne/trains . . Then run the image to create a container which runs our application. The &#39;-p&#39; flag maps port 5000 on localhost in the host to port 5000 in the docker container. . docker run -p 5000:5000 slemasne/trains . You can also run the command with a &#39;-d&#39; detached flag to run the container in the background: . docker run -d -p 5000:5000 slemasne/trains . The application can be accessed on our localhost: . http://localhost:5000/trains .",
            "url": "https://fastpages.fast.ai/tutorials/2018/01/03/flask-app-with-docker.html",
            "relUrl": "/2018/01/03/flask-app-with-docker.html",
            "date": " • Jan 3, 2018"
        }
        
    
  
    
        ,"post6": {
            "title": "SVP100 - Hitting The Wall",
            "content": "In August of 2017 I ran the SVP100. This is a 100KM trail running race starting in Newmarket (Suffolk, UK) and ending in Manning Tree (Essex, UK). In regular distance marathons, its widely believed runners &quot;hit the wall&quot; at around 30KM mark (or 70% through the race). In this notebook, I want to see if the same holds true over a 100KM distance. . From a high level, the code below performs the following: . Scrape results data from the race website (using Beautiful Soup) | Render scraped data into a DataFrame (using Pandas) | Format (or wrangle) the data into formats we can work with | Present results in time series graph (using Seaborn) | . 1. Import packages and set configurations . First, let&#39;s import some packages. We&#39;ll use BeautifulSoup for web scraping, pandas for data analysis, and then seaborn for plotting. . import datetime import time import requests from bs4 import BeautifulSoup import pandas as pd import seaborn as sns import matplotlib.pyplot as plt . Then we set the plotting configuration. I really like the &quot;fivethirtyeight&quot; stylesheet which generates plots in the style used by fivethirtyeight.com. . %matplotlib inline %pylab inline # Set style to fivethirtyeight to create clean and clear looking graphs plt.style.use(&#39;fivethirtyeight&#39;) # Define a dictionary containing default plotting configurations params = {&#39;legend.fontsize&#39;: &#39;small&#39;, &#39;figure.figsize&#39;: (12, 4.5), &#39;axes.labelsize&#39;: &#39;small&#39;, &#39;axes.titlesize&#39;:&#39;medium&#39;, &#39;xtick.labelsize&#39;:&#39;small&#39;, &#39;ytick.labelsize&#39;:&#39;small&#39;} pylab.rcParams.update(params) . Populating the interactive namespace from numpy and matplotlib . Next define some constants that we&#39;ll use in the notebook. First we define a URL which has a table which contains race result data. Then we have some details about the race distance. . BASE_URL = &quot;http://www.svp100.co.uk/results-&quot; YEAR = 2017 # Constants of race details DISTANCE_BETWEEN_CPS = [19.312, 17.702, 16.094, 17.702, 9.657, 13.679, 7.242] CPS_IN_KM = cp_miles = [(i * 1.60934) for i in [12, 23, 33, 44, 50, 58.5, 63]] . 2. Generate unformatted table of race data . In the function below, we request data from the race website and return a DataFrame. For the most part, the DataFrame is unformatted. . def df_builder(base_url=BASE_URL, year=YEAR): &quot;&quot;&quot; This function returns a pandas DataFrame which contain data scraped from the race website. The data is unformatted. Attributes: -- base_url (str): the url which contains race data in HTML year (int): the year for we would like data &quot;&quot;&quot; # Scrape the data from the race website url = base_url + str(year) r = requests.get(url).text soup = BeautifulSoup(r, &#39;lxml&#39;) # Find tables from the html rows = soup.find_all(&#39;tr&#39;)[1:] # Collect and format column names for the dataframe column_html = soup.find_all(&#39;th&#39;)[:] columns = [i.contents[0].lower().replace(&quot;/&quot;,&quot;&quot;).replace(&quot; &quot;, &quot;_&quot;) for i in column_html if i.contents[0]] # Build a dataframe data = [] for line in rows: row = line.find_all(&#39;td&#39;) row_list = [] for counter, value in enumerate(row): row_list.append(row[counter].string) data.append(row_list) # Remove columns we don&#39;t need df = pd.DataFrame(data, columns=columns).drop(columns = [&quot;name&quot;, &quot;club&quot;, &quot;mf&quot;, &quot;bib&quot;, &quot;total_time&quot;]).set_index(&quot;position&quot;) return df . . Generate a DataFrame of race results for the year 2017. . unformatted_df = df_builder(BASE_URL, YEAR) unformatted_df.head(2) . start cp1 cp2 cp3 cp4 cp5 cp6 finish . position . 1 08:30:00 | 09:58:30 | 11:26:51 | 12:58:00 | 14:34:00 | 15:41:00 | 17:04:49 | 17:54:10 | . 2 08:30:00 | 09:56:03 | 11:22:10 | 13:20:00 | 15:14:00 | 16:31:00 | 18:13:51 | 19:09:10 | . Scanning the data, we notice a few things... . The &quot;time&quot; related columns are strings representing a time of day. We&#39;ll need to convert these to datetimes so we can calculate the time (in seconds) between each checkpoint. . | There are some None values which will need to be removed. . | 3. Calculate the time for each runner between checkpoints . In the function below, we calculate the time (in seconds) it took each runner to run between checkpoints. Before we start, however, we want to remove any rows which have None values. . unformatted_df = unformatted_df.dropna().copy() . Now onto our function... . def calculate_time_to_checkpoints(df): &quot;&quot;&quot; This function returns a pandas DataFrame which contains time in seconds it took each runner to reach a checkpoint Attributes: -- df (DataFrame): a dataframe of race results &quot;&quot;&quot; # List out a set of columns which we&#39;ll need to convert into datimes dt_cols = [&quot;start&quot;, &quot;cp1&quot;, &quot;cp2&quot;, &quot;cp3&quot;, &quot;cp4&quot;, &quot;cp5&quot;, &quot;cp6&quot;, &quot;finish&quot;] # Convert these columns to datetimes for col in dt_cols: df[col] = df[col].apply(lambda x: pd.to_datetime(&quot;2017-08-08 &quot; + str(x))) # Then calculate the time in seconds between each checkpoint for start, end in zip(dt_cols, dt_cols[1:]): df[f&quot;time_to_{end}&quot;] = (df[end] - df[start]).apply(lambda x: x.seconds) # Finally lets drop the old &#39;time of day&#39; columns df = df.drop(columns=dt_cols).rename(columns={&quot;time_to_finish&quot;: &quot;time_to_cp7&quot;}).copy() return df . . df_time_to_cp = calculate_time_to_checkpoints(unformatted_df) df_time_to_cp.head(3) . time_to_cp1 time_to_cp2 time_to_cp3 time_to_cp4 time_to_cp5 time_to_cp6 time_to_cp7 . position . 1 5310 | 5301 | 5469 | 5760 | 4020 | 5029 | 2961 | . 2 5163 | 5167 | 7070 | 6840 | 4620 | 6171 | 3319 | . 3 6284 | 6382 | 6534 | 6720 | 4440 | 5869 | 3426 | . 4. Calculate the minutes per KM for each runner between checkpoints . Next we calculate the minutes per km it took each runner to move between checkpoints. . def calc_mins_per_km(df): &quot;&quot;&quot; This function returns a pandas DataFrame which contains min per km it took each runner to move between checkpoints Attributes: -- df (DataFrame): a dataframe of race results &quot;&quot;&quot; df = df.copy() for cp_time, distance in zip(df.columns, DISTANCE_BETWEEN_CPS): df[f&quot;min_per_km_{cp_time[-3:]}&quot;] = df[cp_time].apply(lambda x: (x / distance) / 60) df.drop(columns=[cp_time], inplace=True) df.columns = CPS_IN_KM return df . . The DataFrame below shows how long it took to move between each checkpoint. In this DataFrame we&#39;ve also replaced the checkpoint numbers with their distances in kilometers. . df_min_per_km = calc_mins_per_km(df_time_to_cp) df_min_per_km.head(3) . 19.31208 37.01482 53.10822 70.81096 80.46700 94.14639 101.38842 . position . 1 4.582643 | 4.990961 | 5.663601 | 5.423116 | 6.937972 | 6.127397 | 6.814416 | . 2 4.455779 | 4.864799 | 7.321569 | 6.439950 | 7.973491 | 7.518824 | 7.638314 | . 3 5.423226 | 6.008737 | 6.766497 | 6.326969 | 7.662835 | 7.150864 | 7.884562 | . 5. Calculate averages for three groups . Then we calculate averages for three groups: . All runners | The Top 10 only | Me only | all_runners = pd.DataFrame(df_min_per_km.mean(), columns=[&quot;all_runners&quot;]) top_10_runners = pd.DataFrame(df_min_per_km.head(10).mean(), columns=[&quot;top_10&quot;]) me = pd.DataFrame(df_min_per_km.filter(items=[&#39;7&#39;], axis=0).mean(), columns=[&quot;me&quot;]) . plots = all_runners.join(top_10_runners, lsuffix = &quot;_all&quot;, rsuffix = &quot;_t10&quot;).join(me) plots.index.rename(&quot;kilometer&quot;, inplace=True) plots . all_runners top_10 me . kilometer . 19.31208 6.284585 | 5.366094 | 5.670050 | . 37.01482 7.424970 | 6.037736 | 6.679095 | . 53.10822 7.954279 | 6.728595 | 7.162089 | . 70.81096 8.467717 | 6.880578 | 7.287312 | . 80.46700 11.937517 | 8.594802 | 9.009009 | . 94.14639 9.395034 | 7.693545 | 7.772254 | . 101.38842 9.952413 | 7.907806 | 7.764890 | . 6. Plot results on line chart . Looking at the results below, we can see that all three groups move in a similar pattern, slowing down substantially at 80KM, before picking up the pace for the final 20KM. . plots.plot(y = [&quot;all_runners&quot;,&quot;top_10&quot;,&quot;me&quot;], figsize=(12,7)) plt.title(&#39;Average pace of runners (minutes per km)&#39;) plt.ylabel(&#39;Minutes per km&#39;, fontsize=&quot;small&quot;) plt.xlabel(&#39;Kilometers&#39;) plt.show() .",
            "url": "https://fastpages.fast.ai/tutorials/2018/01/02/svp.html",
            "relUrl": "/2018/01/02/svp.html",
            "date": " • Jan 2, 2018"
        }
        
    
  
    
        ,"post7": {
            "title": "Copying objects in Python",
            "content": "In this tutorial we compare a shallow versus deep copy in Python using the inbuilt copy module. . from copy import copy . 1. Assignment . First we create a list called foo_list which has three items: two ints and one list of ints. We run the in-built id function to check the address of the list object in memory. . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930710693248 . Next we create a second variable called foo_list_two which is assigned to foo_list. We can see that both variables point to the same object in memory. . foo_list_two = foo_list # Check the two variables point to the same object id(foo_list) == id(foo_list_two) . True . foo_list[0] = 11 # Check the second list foo_list_two . [11, 2, [3, 4]] . %reset -f . 3. Shallow copy . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930709728704 . foo_list_two = foo_list.copy() # Check the two variables point to the same object id(foo_list) == id(foo_list_two) . False . foo_list[2][0] = 11 # Check the second list foo_list_two . [1, 2, [11, 4]] . 3. Deep copy . A deep copy creates a new object and recursively adds the copies of nested objects present in the original elements. . from copy import deepcopy . foo_list = [1, 2, [3, 4]] # check the item&#39;s address in memory id(foo_list) . 2930709811328 . foo_list_two = deepcopy(foo_list) # Check the two variables point to different objects id(foo_list) == id(foo_list_two) . False . foo_list[2][0] = 11 # Check that the deep copied list does not update print(foo_list) print(foo_list_two) . [11, 2, [11, 4]] [1, 2, [3, 4]] . foo_list[2][0] = 22 . print(foo_list) print(foo_list_two) . [11, 2, [22, 4]] [1, 2, [3, 4]] .",
            "url": "https://fastpages.fast.ai/tutorials/2018/01/02/copying-objects.html",
            "relUrl": "/2018/01/02/copying-objects.html",
            "date": " • Jan 2, 2018"
        }
        
    
  
    
        ,"post8": {
            "title": "Deploying a Python app with Docker (Part 1)",
            "content": "Deploying a Python app with Docker (Part 1) . In this tutorial, we show how you can build and deploy a really simple Python app using Docker. To demonstrate, we’ll create an API to return details of the TFL train lines in London. We’ll use Flask to build the application. . Create a Flask app . First, create a python flask app which returns details about the TFL trains. This application serves a very basic API with details on London’s TFL trains. . from flask import Flask, jsonify, request import sys import logging logging.basicConfig(level=logging.INFO) app = Flask(__name__) tasks = [ { &#39;id&#39;: 1, &#39;service&#39;: &#39;tube&#39;, &#39;line&#39;: &#39;northern&#39;, &#39;colour&#39;: &#39;black&#39; }, { &#39;id&#39;: 2, &#39;service&#39;: &#39;tube&#39;, &#39;line&#39;: &#39;circle&#39;, &#39;colour&#39;: &#39;red&#39; } ] def shutdown_server(): func = request.environ.get(&#39;werkzeug.server.shutdown&#39;) if func is None: raise RuntimeError(&#39;Not running with the Werkzeug Server&#39;) func() @app.route(&#39;/trains&#39;, methods=[&#39;GET&#39;]) def get_tasks(): return jsonify({&#39;tasks&#39;: tasks}) @app.route(&#39;/&#39;) def hello_world(): return &#39;Welcome to trains API&#39; @app.route(&#39;/exit&#39;) def exit(): message = logging.info(&quot;Stopping application&quot;) shutdown_server() print(&quot;The Flask server has been shutdown.&quot;) if __name__ == &#39;__main__&#39;: app.run(debug=True, host=&#39;0.0.0.0&#39;) .",
            "url": "https://fastpages.fast.ai/tutorials/markdown/2018/01/01/test-markdown-post.html",
            "relUrl": "/markdown/2018/01/01/test-markdown-post.html",
            "date": " • Jan 1, 2018"
        }
        
    
  
    
        ,"post9": {
            "title": "Running a Postgres database locally",
            "content": "In this tutorial, I&#39;ll show how you can run a Postgres (also known as PostgreSQL) database locally and connect to it using pgAdmin. We&#39;ll run the database using a Docker container. . Run the Docker container . First we need to run the postgres container: . docker run --name postgres -d -p 5432:5432 -e POSTGRES_PASSWORD=postgres -e POSTGRES_USER=postgres -e POSTGRES_DB=employees -v ${PWD}/postgres-docker:/var/lib/postgresql/data postgres . Let&#39;s deconstruct this docker command.. . Run a container called postgres using the postgres image: . docker run --name postgres [OPTIONS] postgres | . Run as a detached container, so it runs in the background of your terminal . -d | . Map port 5432 on the localhost to 5432 in the container . -p 5432:5432 | . Next we pass some Postgres specific environment variables to the Postgres container. You will need to use the User and Password to connect. . -e POSTGRES_PASSWORD=postgres | -e POSTGRES_USER=postgres | -e POSTGRES_DB=employees | . Finally map the container volumne to a local volume: . -v ${PWD}/postgres-docker:/var/lib/postgresql/data postgres | . Connect to the Postgres database . Once the container is up-and-running, we can connect to the Postgres database using the sqlalchemy Python package. First, you create an engine object using the Postgres login credentials specified above: . from sqlalchemy import create_engine db=create_engine(&quot;postgresql://postgres:postgres@localhost:5432/employees&quot;) . Write an SQL string to: . 1. Create a new table called employee_details 2. Populate this table with some data . bootstrap_sql = &quot;&quot;&quot; CREATE TABLE EMPLOYEE_DETAILS( ID INT PRIMARY KEY NOT NULL, NAME TEXT NOT NULL, AGE INT NOT NULL, ADDRESS CHAR(50), SALARY REAL, JOIN_DATE DATE ); INSERT INTO EMPLOYEE_DETAILS (ID,NAME,AGE,ADDRESS,SALARY,JOIN_DATE) VALUES (1, &#39;John&#39;, 32, &#39;London&#39;, 20000.00,&#39;2001-07-13&#39;); INSERT INTO EMPLOYEE_DETAILS (ID,NAME,AGE,ADDRESS,SALARY,JOIN_DATE) VALUES (2, &#39;David&#39;, 25, &#39;Dublin&#39;, 30000.00, &#39;2007-12-13&#39;); INSERT INTO EMPLOYEE_DETAILS (ID,NAME,AGE,ADDRESS,SALARY,JOIN_DATE) VALUES (3, &#39;Sarah&#39;, 25, &#39;Edinburgh&#39;, 40000.00, &#39;2007-12-13&#39;); &quot;&quot;&quot; . Pass that SQL string to the database engine object: . with db.connect() as con: try: rs = con.execute(bootstrap_sql) ## TODO: Add proper error handling except: pass . View results in pgAdmin . Register a new server using the details passed to the docker container above: . . And view the results: . .",
            "url": "https://fastpages.fast.ai/tutorials/docker/postgres/2018/01/01/run-pg-locally.html",
            "relUrl": "/docker/postgres/2018/01/01/run-pg-locally.html",
            "date": " • Jan 1, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi There! I am Stephen Lemasney. I work in FinTech as a Sales Engineer. In this blog I share some Python and data tutorials. .",
          "url": "https://fastpages.fast.ai/tutorials/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://fastpages.fast.ai/tutorials/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}