# SVP100 - Hitting The Wall

In August of 2017 I ran the SVP100. This is a 100KM trail running race starting in Newmarket (Suffolk, UK) and ending in Manning Tree (Essex, UK). In regular distance marathons, its widely believed runners "hit the wall" at around 30KM mark (or 70% through the race). In this notebook, I want to see if the same holds true over a 100KM distance.

From a high level, the code below performs the following:

1. Scrape results data from the race website (using Beautiful Soup)

2. Render scraped data into a DataFrame (using Pandas)

3. Format (or wrangle) the data into formats we can work with

4. Present results in time series graph (using Seaborn)

## 1. Import packages and set configurations

First, let's import some packages. We'll use BeautifulSoup for web scraping, pandas for data analysis, and then seaborn for plotting. 


```python
# Import the packages we'll use for our analysis
import datetime
import time
import requests

from bs4 import BeautifulSoup
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt
```

Then we set the plotting configuration. I really like the "fivethirtyeight" stylesheet which generates plots in the style used by fivethirtyeight.com.


```python
# Use line magic function to enable matplotlib to work interactively with iPython

%matplotlib inline
%pylab inline

# Set style to fivethirtyeight to create clean and clear looking graphs

plt.style.use('fivethirtyeight')

# Define a dictionary containing default plotting configurations

params = {'legend.fontsize': 'small',
          'figure.figsize': (12, 4.5),
         'axes.labelsize': 'small',
         'axes.titlesize':'medium',
         'xtick.labelsize':'small',
         'ytick.labelsize':'small'}

pylab.rcParams.update(params)
```

    Populating the interactive namespace from numpy and matplotlib
    


```python
BASE_URL = "http://www.svp100.co.uk/results-"
YEAR = 2017
```

## 2. Generate unformatted table of race data


```python
def df_builder(base_url=BASE_URL, year=YEAR):
    
    """
    This function returns a pandas DataFrame which contain data scraped from the race website.
    The data is unformatted.
    
    Attributes:
    -----------
    base_url: the url which contains race data in HTML
    year: the year for we would like data
    """
    
    # Scrape the data from the race website
    url = base_url + str(year)
    r = requests.get(url).text
    soup = BeautifulSoup(r, 'lxml')
    
    # Find tables from the html
    rows = soup.find_all('tr')[1:]
    
    # Collect and format column names for the dataframe
    column_html = soup.find_all('th')[:]    
    columns = [i.contents[0].lower().replace("/","").replace(" ", "_") for i in column_html if i.contents[0]]

    # Build a dataframe
    data = []
    for line in rows:
        row = line.find_all('td')
        row_list = []
        for counter, value in enumerate(row):
            row_list.append(row[counter].string)
        data.append(row_list)
            
    return pd.DataFrame(data, columns=columns).drop(columns = ["name", "club"]).set_index("position")

```


```python
unformatted_df = df_builder(BASE_URL, YEAR)
```


```python
unformatted_df.tail(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bib</th>
      <th>mf</th>
      <th>start</th>
      <th>cp1</th>
      <th>cp2</th>
      <th>cp3</th>
      <th>cp4</th>
      <th>cp5</th>
      <th>cp6</th>
      <th>finish</th>
      <th>total_time</th>
    </tr>
    <tr>
      <th>position</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>91</th>
      <td>162</td>
      <td>Female</td>
      <td>07:00:00</td>
      <td>09:51:33</td>
      <td>DNF</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>92</th>
      <td>7</td>
      <td>Male</td>
      <td>08:30:00</td>
      <td>10:23:05</td>
      <td>DNF</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
</div>



## 3. Clean the table of race data


```python
dt_cols = ["start", "cp1", "cp2", "cp3", "cp4", "cp5", "cp6", "finish", "total_time"]
unformatted_df = unformatted_df.dropna()

```


```python


for col in dt_cols:
    
    unformatted_df[col] = unformatted_df[col].apply(lambda x: pd.to_datetime("2017-08-08 " + str(x)))
        
    
    
```


```python
unformatted_df["time2cp1"] = unformatted_df.cp1 - unformatted_df.start
```


```python
unformatted_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bib</th>
      <th>mf</th>
      <th>start</th>
      <th>cp1</th>
      <th>cp2</th>
      <th>cp3</th>
      <th>cp4</th>
      <th>cp5</th>
      <th>cp6</th>
      <th>finish</th>
      <th>total_time</th>
      <th>time2cp1</th>
    </tr>
    <tr>
      <th>position</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>19</td>
      <td>Male</td>
      <td>2017-08-08 08:30:00</td>
      <td>2017-08-08 09:58:30</td>
      <td>2017-08-08 11:26:51</td>
      <td>2017-08-08 12:58:00</td>
      <td>2017-08-08 14:34:00</td>
      <td>2017-08-08 15:41:00</td>
      <td>2017-08-08 17:04:49</td>
      <td>2017-08-08 17:54:10</td>
      <td>2017-08-08 09:24:10</td>
      <td>0 days 01:28:30</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20</td>
      <td>Male</td>
      <td>2017-08-08 08:30:00</td>
      <td>2017-08-08 09:56:03</td>
      <td>2017-08-08 11:22:10</td>
      <td>2017-08-08 13:20:00</td>
      <td>2017-08-08 15:14:00</td>
      <td>2017-08-08 16:31:00</td>
      <td>2017-08-08 18:13:51</td>
      <td>2017-08-08 19:09:10</td>
      <td>2017-08-08 10:39:10</td>
      <td>0 days 01:26:03</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13</td>
      <td>Female</td>
      <td>2017-08-08 08:30:00</td>
      <td>2017-08-08 10:14:44</td>
      <td>2017-08-08 12:01:06</td>
      <td>2017-08-08 13:50:00</td>
      <td>2017-08-08 15:42:00</td>
      <td>2017-08-08 16:56:00</td>
      <td>2017-08-08 18:33:49</td>
      <td>2017-08-08 19:30:55</td>
      <td>2017-08-08 11:00:55</td>
      <td>0 days 01:44:44</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
      <td>Male</td>
      <td>2017-08-08 08:30:00</td>
      <td>2017-08-08 10:15:26</td>
      <td>2017-08-08 12:08:01</td>
      <td>2017-08-08 13:52:00</td>
      <td>2017-08-08 15:52:00</td>
      <td>2017-08-08 17:12:00</td>
      <td>2017-08-08 18:53:46</td>
      <td>2017-08-08 19:53:37</td>
      <td>2017-08-08 11:23:37</td>
      <td>0 days 01:45:26</td>
    </tr>
    <tr>
      <th>5</th>
      <td>143</td>
      <td>Male</td>
      <td>2017-08-08 07:00:00</td>
      <td>2017-08-08 08:49:35</td>
      <td>2017-08-08 10:44:27</td>
      <td>2017-08-08 12:33:00</td>
      <td>2017-08-08 14:41:00</td>
      <td>2017-08-08 16:02:00</td>
      <td>2017-08-08 17:40:23</td>
      <td>2017-08-08 18:36:58</td>
      <td>2017-08-08 11:36:58</td>
      <td>0 days 01:49:35</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>63</th>
      <td>186</td>
      <td>Female</td>
      <td>2017-08-08 07:00:00</td>
      <td>2017-08-08 09:15:33</td>
      <td>2017-08-08 11:53:05</td>
      <td>2017-08-08 14:17:00</td>
      <td>2017-08-08 17:03:00</td>
      <td>2017-08-08 18:56:00</td>
      <td>2017-08-08 21:01:02</td>
      <td>2017-08-08 22:21:22</td>
      <td>2017-08-08 15:21:22</td>
      <td>0 days 02:15:33</td>
    </tr>
    <tr>
      <th>64</th>
      <td>120</td>
      <td>Male</td>
      <td>2017-08-08 07:00:00</td>
      <td>2017-08-08 09:15:41</td>
      <td>2017-08-08 11:53:00</td>
      <td>2017-08-08 14:17:00</td>
      <td>2017-08-08 17:03:00</td>
      <td>2017-08-08 18:56:00</td>
      <td>2017-08-08 21:01:04</td>
      <td>2017-08-08 22:21:22</td>
      <td>2017-08-08 15:21:22</td>
      <td>0 days 02:15:41</td>
    </tr>
    <tr>
      <th>65</th>
      <td>104</td>
      <td>Male</td>
      <td>2017-08-08 07:00:00</td>
      <td>2017-08-08 09:15:30</td>
      <td>2017-08-08 11:53:08</td>
      <td>2017-08-08 14:17:00</td>
      <td>2017-08-08 17:03:00</td>
      <td>2017-08-08 18:56:00</td>
      <td>2017-08-08 21:01:13</td>
      <td>2017-08-08 22:21:22</td>
      <td>2017-08-08 15:21:22</td>
      <td>0 days 02:15:30</td>
    </tr>
    <tr>
      <th>66</th>
      <td>121</td>
      <td>Female</td>
      <td>2017-08-08 07:00:00</td>
      <td>2017-08-08 09:14:56</td>
      <td>2017-08-08 11:41:59</td>
      <td>2017-08-08 14:10:00</td>
      <td>2017-08-08 16:54:00</td>
      <td>2017-08-08 18:41:00</td>
      <td>2017-08-08 21:00:25</td>
      <td>2017-08-08 22:27:51</td>
      <td>2017-08-08 15:27:51</td>
      <td>0 days 02:14:56</td>
    </tr>
    <tr>
      <th>67</th>
      <td>154</td>
      <td>Male</td>
      <td>2017-08-08 07:00:00</td>
      <td>2017-08-08 09:14:43</td>
      <td>2017-08-08 11:42:09</td>
      <td>2017-08-08 14:10:00</td>
      <td>2017-08-08 16:57:00</td>
      <td>2017-08-08 18:41:00</td>
      <td>2017-08-08 21:00:58</td>
      <td>2017-08-08 22:27:51</td>
      <td>2017-08-08 15:27:51</td>
      <td>0 days 02:14:43</td>
    </tr>
  </tbody>
</table>
<p>67 rows × 12 columns</p>
</div>




```python
unformatted_df.cp3 = unformatted_df.cp3.apply(lambda x: str(x))

unformatted_df.cp3 = pd.to_datetime(unformatted_df.cp3)
```


```python
unformatted_df.cp3
```




    position
    1    2022-09-11 12:58:00
    2    2022-09-11 13:20:00
    3    2022-09-11 13:50:00
    4    2022-09-11 13:52:00
    5    2022-09-11 12:33:00
                 ...        
    63   2022-09-11 14:17:00
    64   2022-09-11 14:17:00
    65   2022-09-11 14:17:00
    66   2022-09-11 14:10:00
    67   2022-09-11 14:10:00
    Name: cp3, Length: 67, dtype: datetime64[ns]



## Create class for scraping and organising data


```python
# Define a class Results for creating Pandas dataframe objects of scrapped data from race results website 

class raceResults():
    
    """
    This class returns pandas DataFrame objects which contain data scraped from the race website.
    
    Attributes:
    -----------
    base_url: the url which contains race data in HTML
    year: the year for we would like data
    columns: the column headers for data to be scraped
    check_points: column headers used to calculate time between checkpoints
    """
    
    def __init__(self, base_url, year, columns, check_points):
        self.base_url = base_url
        self.year = year
        self.columns = columns
        self.check_points = check_points
        
    def basic_table(self):
        url = base_url + str(self.year)
        r = requests.get(url).text
        soup = BeautifulSoup(r, 'lxml')

        lines = soup.find_all('tr')[1:]
        
        data = []
        for line in lines:
            row = line.find_all('td')
            row_list = []
            for counter, value in enumerate(row):
                row_list.append(row[counter].string)
            data.append(row_list)

        return pd.DataFrame(data, columns = columns).set_index(columns[1])

    def df_results(self):
        df_results = self.basic_table()
    
        total = []
        for i in df_results["total"]:
            if i is not None:
                total.append(str(i))
            else:
                total.append(0)

        df_results["total"] = total

        def str2_min(x):
            ftr = [3600,60,1]
            if not x == 0:
                total_seconds = sum([a*b for a,b in zip(ftr, map(int,x.split(':')))])
                return round((total_seconds / 60),2)

        df_results['total_min'] = df_results['total'].map(str2_min)
        df_results["average_min"] = round(df_results["total_min"].mean(), 2)
        df_results["start"] = datetime.datetime(2017, 8, 12, 7, 0 ,0)

        cps = self.check_points 

        def checkpoint2_datetime(cp):
            df_results[cp] = pd.to_datetime(df_results[cp], format = "%H:%M:%S", errors="coerce")
            df_results[cp] = df_results[cp].apply(lambda dt: dt.replace(year = 2017, month = 8, day=12))
            return df_results[cp]
    
        for i in cps: 
            df_results[i] = checkpoint2_datetime(i)
            
        df_results["time2cp1"] = df_results["cp1"] - df_results["start"]
        df_results["time2cp2"] = df_results["cp2"] - df_results["cp1"] 
        df_results["time2cp3"] = df_results["cp3"] - df_results["cp2"] 
        df_results["time2cp4"] = df_results["cp4"] - df_results["cp3"] 
        df_results["time2cp5"] = df_results["cp5"] - df_results["cp4"]
        df_results["time2cp6"] = df_results["cp6"] - df_results["cp5"]
        df_results["time2end"] = df_results["finish"] - df_results["cp6"]
        
        return df_results
    
    
    def top_runners(self, x = 10):
        df_top = self.df_results()[:x]
        return df_top
    
    def target_runners(self, runner):
        df_runner = self.df_results().loc[runner]
        df_runner = pd.DataFrame(df_runner)
        return df_runner
```


```python
# Next define a standalone function for creating averages from the Results() objects

def average_pace(df):

    df = pd.DataFrame(df)

    convert_km = 1.60934
    cp = ["time2cp1", "time2cp2", "time2cp3", "time2cp4", "time2cp5", "time2cp6", "time2end"]
    cp_miles = [12, 23, 33, 44, 50, 58.5, 63]
    cp_miles_s = [12,11,10,11,6,8.5,4.5]
    cp_distances = pd.DataFrame({"cp_miles": cp_miles, "cp_miles_s": cp_miles_s}, index = cp)
    cp_distances["cp_km"] = cp_distances["cp_miles"] * convert_km
    cp_distances["cp_km_s"] = cp_distances["cp_miles_s"] * convert_km

    df_time2cp = pd.DataFrame(df, columns= cp)
    df_averages = {}
    for i in cp: df_averages[str(i)] = df_time2cp[str(i)].mean()

    df_averages = pd.Series(df_averages, name = "2017")
    df_averages = pd.DataFrame(df_averages)
    df_averages = (df_averages.join(cp_distances))
    df_averages["2017_min"] = [(i.total_seconds()/60) for i in df_averages["2017"]]
    df_averages["min_km"] = df_averages["2017_min"]/df_averages["cp_km_s"]

    return df_averages
```

## Define some variables we will pass to our class


```python
# Race website URL:

base_url = r'http://www.svp100.co.uk/results-'

# Column headers for the DataFrame scraped directly from the website:

columns = ["pos", "name", "bib", "gender", "start", "club", 
           "cp1", "cp2", "cp3", "cp4", "cp5", "cp6", "finish", "total"] 

# List of new columns we'll add to the DataFrame for our analysis

check_points = ["cp1","cp2","cp3","cp4","cp5","cp6","finish"]
```

## Initialize a Results() object with results from 2017 race¶


```python
results = raceResults(base_url, 2017, columns, check_points)
all_runners = results.df_results()
all_runners = average_pace(all_runners)
```


```python
top_3 = results.top_runners(10)
top_3 = average_pace(top_3)
```


```python
me = results.target_runners("Stephen Lemasney")
```


```python
plots = all_runners.join(top_3, lsuffix = "_all", rsuffix  = "_t3")
plots = plots.join(me, rsuffix="_me" )
plots["2017_me"] = [(i.total_seconds()/60) for i in plots["Stephen Lemasney"]]
plots["min_km_me"] = plots["2017_me"]/plots["cp_km_s_all"]
plots = plots.rename(columns = {"min_km_all":"All Runners","min_km_t3":"Top 10","min_km_me":"Me"})
```

## Plot the results using "FiveThirtyEight" styling


```python
plots.plot(y = ["All Runners","Top 10","Me"], x = "cp_km_all", figsize=(12,7))
plt.title('Average pace of runners (minutes per km)')
plt.ylabel('Minutes per km', fontsize="small")
plt.xlabel('Kilometers')
plt.show()
```


    
![png](2018-03-02-svp_files/2018-03-02-svp_29_0.png)
    

